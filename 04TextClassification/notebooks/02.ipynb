{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6c0f4e7-eb9f-42ab-b9a2-29944bc720e2",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "**Author**: Gunnvant\n",
    "\n",
    "**Description**: Classification training loop using pytorch\n",
    "\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f88441f-82e0-4fac-a310-b25b23271e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ef091f6-a2d6-4eaa-9084-c6312a0bed1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7d2651-4eee-475e-a4c8-bd7105700042",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_data = load_dataset(\"csv\",data_files=\"../dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413bdba2-0b69-4fb5-87ef-b5c8be9994d6",
   "metadata": {},
   "source": [
    "### Dataprep\n",
    "- train,test and evaluation split\n",
    "- tokenize and pad the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e8d905e-cce6-4705-a043-042f4c74058a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ckpt = \"distilbert-base-uncased\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(ckpt,num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "778a8482-b2b4-4881-a825-2678bfd05977",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train_test=raw_data['train'].train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef94036f-4c99-430e-9312-a5e226cc6a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_test_valid = raw_train_test['test'].train_test_split(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c14c4b50-23ae-47de-a75d-d93f3cb5c4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict\n",
    "raw_train_test_valid = DatasetDict({\n",
    "'train':raw_train_test['train'],\n",
    "'test':raw_test_valid['train'],\n",
    "'valid':raw_train_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e05f6c21-11f3-43d5-989f-c3cfa2a65925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70bb5e61-42bc-45c5-88da-50c9686e6012",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'How does harry potter get down a hill? walking. jk. rowling.',\n",
       " 'humor': True}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_test_valid['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c557be-41bf-4c3d-b975-51b0a547e9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_label(example):\n",
    "    example['labels'] = int(example['humor'])\n",
    "    return example\n",
    "def preprocess(example):\n",
    "    return tokenizer(example['text'],padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7745d030-4384-49e2-b8ff-238a11f5e327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████| 160000/160000 [00:07<00:00, 21036.49 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████| 32000/32000 [00:01<00:00, 22161.36 examples/s]\n",
      "Map: 100%|████████████████████████████████████████████████████████| 40000/40000 [00:01<00:00, 22140.16 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████| 160000/160000 [00:23<00:00, 6906.70 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████| 32000/32000 [00:04<00:00, 7073.69 examples/s]\n",
      "Map: 100%|█████████████████████████████████████████████████████████| 40000/40000 [00:05<00:00, 7186.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "preprocessed_dataset = raw_train_test_valid.map(get_label)\n",
    "preprocessed_dataset = preprocessed_dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7650354c-ae09-4919-95c3-cbed02e19748",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'How does harry potter get down a hill? walking. jk. rowling.',\n",
       " 'humor': True,\n",
       " 'labels': 1,\n",
       " 'input_ids': [101,\n",
       "  2129,\n",
       "  2515,\n",
       "  4302,\n",
       "  10693,\n",
       "  2131,\n",
       "  2091,\n",
       "  1037,\n",
       "  2940,\n",
       "  1029,\n",
       "  3788,\n",
       "  1012,\n",
       "  1046,\n",
       "  2243,\n",
       "  1012,\n",
       "  5216,\n",
       "  2989,\n",
       "  1012,\n",
       "  102],\n",
       " 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42d62f69-caf9-41ba-9b3e-9f01aafa5881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_dataset = preprocessed_dataset.remove_columns(['text','humor'])\n",
    "preprocessed_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "110da170-38cc-4b37-a189-897ab3d5bf5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "    preprocessed_dataset[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    preprocessed_dataset[\"valid\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb916753-f685-47a7-b6a2-b60fe796ec00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b1 = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d92247a1-dc07-4ee0-bb45-478159d82a92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 0, 0, 0, 0, 0, 1, 1]), 'input_ids': tensor([[  101,  2129,  2079,  2017,  2113,  2065,  2017,  1005,  2128,  2012,\n",
       "          1037,  5637, 26375,  1029,  1996,  2980, 16168,  2015,  5510,  2066,\n",
       "          4485,  1012,   102],\n",
       "        [  101,  5294,  1010,  4121,  8398,  4171,  2933,  1024,  2028,  2062,\n",
       "          4872,  2921,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101, 16941,  4491,  2006,  5085,  2024,  3976,  1997,  8169,  1999,\n",
       "          3617,  3690,   102,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  1045,  2439,  3635,  1024,  8201,  3766,  2439,  6445,  7038,\n",
       "          2000,  5547, 11888,  3255,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2129,  2115, 19857,  6593, 24133,  3637,  6134,  2003, 23217,\n",
       "          2075,  2115,  6897,  5119,   102,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  5163, 20539,  1010, 29044, 28844,  3693,  2047,  6655,  2186,\n",
       "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2040,  1005,  1055,  1996,  2087, 18804,  2447,  2006,  1037,\n",
       "          2374,  2136,  1029,  1996, 18975,  2121,  1012,   102,     0,     0,\n",
       "             0,     0,     0],\n",
       "        [  101,  2054,  2015,  1996,  4489,  2090,  1037, 16522,  1998,  1037,\n",
       "          2879,  7464,  2879, 10158,  2272,  2188,  2013,  3409,   102,     0,\n",
       "             0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd5c1bb-ed61-4cbb-bdcc-6473eaa11e73",
   "metadata": {},
   "source": [
    "### Model check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9252117-4b72-456f-b143-b25d44567b31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = model(**b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de5dec65-80e0-4611-9ad2-3a8745fe83b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequenceClassifierOutput(loss=tensor(0.7317, grad_fn=<NllLossBackward0>), logits=tensor([[-0.1140,  0.0048],\n",
       "        [-0.1782,  0.0135],\n",
       "        [-0.1257,  0.0554],\n",
       "        [-0.1708,  0.0559],\n",
       "        [-0.1644,  0.0187],\n",
       "        [-0.1333, -0.0180],\n",
       "        [-0.1235, -0.0148],\n",
       "        [-0.1320, -0.0266]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46bfc5de-f768-4aa4-8030-8c7dd54bb53b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gunnvantsaini/miniforge3/envs/huggingface/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000389ad-2a05-4357-b10f-97710655d8e9",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "413d27cb-264a-4196-b746-2b0a5460b968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_scheduler\n",
    "num_epochs = 1\n",
    "num_training_steps = num_epochs * len(train_dataloader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")\n",
    "print(num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e146c8e-f8f0-4653-a257-15958e04e4b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384fa2a6-107f-45de-8d9e-55b769071789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b990f-071f-4418-8629-41007fd7a8e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
